Für die Behandlung der Anforderungen in Mehrprogrammbetriebssystemen
sind primitive Ad-hoc-Lösungen nicht mehr möglich. Das Verständnis des
Gesamtsystems ist nicht mehr durch die Beschreibung des Verhaltens der
CPU zu jedem Zeitpunkt möglich, da das Verhalten der CPU in
Mehrbenutzersystemen im Mehrprogrammbetrieb stark von nicht
vorhersagbaren externen Ereignissen (Unterbrechungen) abhängig ist. Das
Betriebssystem wird als Ansammlung von funktionellen Einheiten
betrachtet, die zunächst unabhängig voneinander arbeiten aber über
wohldefinierte Schnittstellen miteinander kommunizieren müssen. Diese
funktionellen Einheiten bezeichnet man als Prozesse.

* Prozessbegriff
  :PROPERTIES:
  :CUSTOM_ID: prozessbegriff
  :END:

**** Typische Merkmale von Prozessen:
     :PROPERTIES:
     :CUSTOM_ID: typische-merkmale-von-prozessen
     :END:

 \\

-  brauchen Prozessor

-  enthalten jeweils ein sequentielles Programm

-  können grundsätzlich parallel ablaufen

Zur Abgrenzung zum Begriff /Benutzerauftrag/ (/Job/): Zur Abarbeitung
eines Benutzerauftrags sind in der Regel mehrere Prozesse notwendig.

**** Formen der Parallelität
     :PROPERTIES:
     :CUSTOM_ID: formen-der-parallelität
     :END:

-  mehrere Prozesse laufen auf unterschiedlichen Prozessoren ab\\
   (tatsächlich parallel)

-  ein Prozessor wird "scheibchenweise" den Prozessen zugeordnet, so dass
   diese "überlappt" ablaufen\\
   (quasi-parallel)

Die im Zusammenhang mit der Parallelität von Prozessen auftretenden
Probleme sind davon aber unabhängig.

* Synchronisation konkurrierender und kooperierender Prozesse
  :PROPERTIES:
  :CUSTOM_ID: synchronisation-konkurrierender-und-kooperierender-prozesse
  :END:

** Problem des wechselseitigen Ausschlusses
   :PROPERTIES:
   :CUSTOM_ID: problem-des-wechselseitigen-ausschlusses
   :END:

Das Problem des wechselseitigen Ausschlusses (/mutual exclusion/) wurde
erstmals 1965 von Edsger W. Dijkstra formuliert.

**** Beispiel 1:
     :PROPERTIES:
     :CUSTOM_ID: beispiel-1
     :END:

Zwei zyklische Prozesse $p_1$ und $p_2$ benutzen von Zeit zu Zeit ein
Magnetband. Es steht nur ein Gerät zur Verfügung, das nicht von mehr als
einem Prozess gleichzeitig benutzt werden kann.

***** 1. Lösungsversuch:
      :PROPERTIES:
      :CUSTOM_ID: lösungsversuch
      :END:

man definiert eine boolesche Variable =frei=\\

\\
$p_1$:

=== 001 wiederhole\\
002 wiederhole bis frei;\\
003 frei := false;\\
004 benutze(magnetband)\\
005 frei := true;\\
$\vdots$ $\vdots$\\
FFF ständig\\

\\
$p_2$:

=== 001 wiederhole\\
002 wiederhole bis frei;\\
003 frei := false;\\
004 benutze(magnetband)\\
005 frei := true;\\
$\vdots$ $\vdots$\\
FFF ständig\\

***** Problem:
      :PROPERTIES:
      :CUSTOM_ID: problem
      :END:

Wenn $p_1$ und $p_2$ parallel ablaufen, können sie auch gleichzeitig das
Magnetband als frei erkennen. Das gleiche Problem kann auch bei
quasi-parallel ablaufenden Prozessen auftreten, da jeder Prozess zwischen
=002= und =003= unterbrochen werden kann.

Weiterer Nachteil dieser "Lösung": Durch die Warteschleife wird
Prozessorzeit beansprucht (/busy waiting/).

***** 2. Lösungsversuch
      :PROPERTIES:
      :CUSTOM_ID: lösungsversuch-1
      :END:

man definiert eine boolesche Variable =p1anderReihe=\\

\\
$p_1$:

=== 001 wiederhole\\
002 wiederhole bis p1anderReihe;\\
003 benutze(magnetband)\\
004 p1anderReihe := false;\\
$\vdots$ $\vdots$\\
FFF ständig\\

\\
$p_2$:

=== 001 wiederhole\\
002 wiederhole bis nicht p1anderReihe;\\
003 benutze(magnetband)\\
004 p1anderReihe := true;\\
$\vdots$ $\vdots$\\
FFF ständig\\

Ein wechselseitiger Ausschluss ist zwar gewährleistet, allerdings müssen
die Prozesse das Magnetband abwechselnd benutzen. Beide Prozesse müssen
außerdem "am Leben" bleiben. /Busy waiting/ tritt auch hier auf.

***** 3. Lösungsversuch
      :PROPERTIES:
      :CUSTOM_ID: lösungsversuch-2
      :END:

Definition zweier boolesche Variablen =p1istdran= und =p2istdran=

Initialisierung:

= p1istdran := false\\
p2istdran := false

p1:

=wiederhole\\
p1istdran := true\\
wiederhole bis nicht p2istdran\\
benutze(magnetband)\\
p1istdran := false\\
$\vdots$\\
ständig

p2:

=wiederhole\\
p2istdran := true\\
wiederhole bis nicht p1istdran\\
benutze(magnetband)\\
p2istdran := false\\
$\vdots$\\
ständig

\\
Wechselseitiger Ausschluss ist zwar garantiert, es besteht aber die
Gefahr der Verklemmung (/deadlock/).

Anforderungen an eine Lösung für das Problem des wechselseitigen
Ausschlusses:

1. Das Betriebsmittel wird nach endlicher Zeit zugewiesen.

2. Ein Prozess gibt das Betriebsmittel nach endlicher Zeit wieder frei.

3. Ein Prozess, der wartet, soll keine Rechenzeit verbrauchen.

4. Eine Problemlösung soll von den Prozessen in eine gemeinsame Umgebung
   verlagert werden.

Das grundsätzliche Problem resultiert aus der "unkontrollierten"
Benutzung gemeinsamer Daten.

Weitere Beispiele für das Auftreten des Problems des wechselseitigen
Ausschlusses:

1. Veränderung von Datensätzen in einer von mehreren Prozessen gemeinsam
   benutzten Datei

2. gemeinsame Benutzung von Unterprogrammen mit lokalen Variablen für
   Zwischenergebnisse

**** Definition:
     :PROPERTIES:
     :CUSTOM_ID: definition
     :END:

Programmabschnitte, in denen sich zu einem Zeitpunkt nur jeweils ein
Prozess befinden darf, heißen /kritische Abschnitte/ (/critical
sections/).

**** Lösung: =P=- und =V=-Operationen nach Edsger W. Dijkstra
     :PROPERTIES:
     :CUSTOM_ID: lösung-p--und-v-operationen-nach-edsger-w.-dijkstra
     :END:

 \\
=P= und =V= sind zwei Operationen auf einer gemeinsamen Variablen,
genannt /Semaphorvariable/. Jedem kritischen Abschnitt wird eine
Semaphore zugeordnet.

**** Definition von =P= und =V=:
     :PROPERTIES:
     :CUSTOM_ID: definition-von-p-und-v
     :END:

#+BEGIN_EXAMPLE
    P(s):
       wenn s=1
       dann s:=0
       sonst blockiere den aufrufenden Prozess
             und schalte auf anderen Prozess um
        
    V(s):
       wenn ein Prozess auf s wartet
       dann loese den Prozess aus Wartezustand
       sonst s:=1
#+END_EXAMPLE

Beispiel für die Sicherung eines kritischen Abschnitts (Benutzung eines
Magnetbandgeräts) durch eine Semaphore =s=:

= P(s)\\
benutze(magnetband)\\
V(s)

=P=- und =V=-Operationen sind selbst kritische Abschnitte und müssen
atomar sein (dürfen nicht selbst unterbrochen werden). Es handelt sich
aber um kurze kritische Abschnitte, die im Systemkern realisiert werden,
wo wechselseitiger Ausschluss einfach zu implementieren ist. Sie werden
häufig mithilfe eines Spezialbefehls des Prozessors realisiert, wobei
ein aktives Warten in Kauf genommen wird. Dazu wird eine Sperrvariable
=pv= mit folgender Bedeutung eingeführt:

| =pv=1=   | :   | =P=- und =V=-Operationen können ausgeführt werden         |
| =pv=0=   | :   | =P=- und =V=-Operationen können nicht ausgeführt werden   |

Der Spezialbefehl =teste_und_setze(pv)= ist eine unteilbare Operation,
die folgendermaßen arbeitet:

#+BEGIN_EXAMPLE
       wiederhole solange pv = 0; (* tue nichts, busy waiting *)\\
       pv := 0
#+END_EXAMPLE

Mithilfe dieses Befehls werden nun zwei modifizierte Operationen =P’=
und =V’= eingeführt, die dann zur Sicherung eines kritischen Abschnitts
eingesetzt werden können.

=P'(s)\\
teste\_und\_setze(pv)\\
P(s)\\
pv:=1

=V'(s)\\
teste\_und\_setze(pv)\\
V(s)\\
pv:=1

Bisher wurden nur um gemeinsame Betriebsmittel konkurrierende Prozesse
betrachtet, die sonst nichts miteinander zu tun hatten.

** Synchronisation kooperierender Prozesse
   :PROPERTIES:
   :CUSTOM_ID: synchronisation-kooperierender-prozesse
   :END:

Kooperation zwischen Prozessen kann z.B. heißen, dass Nachrichten
zwischen einem Erzeuger und einem Verbraucher ausgetauscht werden
(/producer-consumer-pro"-blem/).

Nachrichtenaustausch soll gepuffert erfolgen, um Erzeuger und
Verbraucher bezüglich ihrer Arbeitsgeschwindigkeit zu entkoppeln.
Ringpuffer fester Größe kann nur eine feste Anzahl von Nachrichten
speichern. Abbildung [Ringpuffer] zeigt einen teilweise gefüllten
Ringpuffer mit zwei Zeigern, =c= für den Verbraucher und =p= für den
Erzeuger. Beide Prozesse bearbeiten den Puffer im Uhrzeigersinn. Durch
die Prozesssynchonisation muss verhindert werden, dass sie sich gegenseitig
"überholen".

(9,7) (4,6.75)(1,0)1 (5,6.75)(3,-1)0.75 (5.75,6.5)(3,-2)0.75
(6.5,6)(1,-1)0.5 (7,5.5)(2,-3)0.5 (7.5,4.75)(1,-3)0.25 (7.75,4)(0,-1)1
(7.75,3)(-1,-3)0.25 (7.5,2.25)(-2,-3)0.5 (7,1.5)(-1,-1)0.5
(6.5,1)(-3,-2)0.75 (5.75,0.5)(-3,-1)0.75 (5,0.25)(-1,0)1
(4,0.25)(-3,1)0.75 (3.25,0.5)(-3,2)0.75 (2.5,1)(-1,1)0.5
(2,1.5)(-2,3)0.5 (1.5,2.25)(-1,3)0.25 (1.25,3)(0,1)1 (1.25,4)(1,3)0.25
(1.5,4.75)(2,3)0.5 (2,5.5)(1,1)0.5 (2.5,6)(3,2)0.75 (3.25,6.5)(3,1)0.75

(4.25,6)(1,0)0.5 (4.75,6)(3,-1)0.75 (5.5,5.75)(2,-1)0.5 (6,5.5)(1,-1)0.5
(6.5,5)(1,-2)0.25 (6.75,4.5)(1,-3)0.25 (7,3.75)(0,-1)0.5
(7,3.25)(-1,-3)0.25 (6.75,2.5)(-1,-2)0.25 (6.5,2)(-1,-1)0.5
(6,1.5)(-2,-1)0.5 (5.5,1.25)(-3,-1)0.75 (4.75,1)(-1,0)0.5
(4.25,1)(-3,1)0.75 (3.5,1.25)(-2,1)0.5 (3,1.5)(-1,1)0.5
(2.5,2)(-1,2)0.25 (2.25,2.5)(-1,3)0.25 (2,3.25)(0,1)0.5
(2,3.75)(1,3)0.25 (2.25,4.5)(1,2)0.25 (2.5,5)(1,1)0.5 (3,5.5)(2,1)0.5
(3.5,5.75)(3,1)0.75

(1.25,4)(0.25,0.75)2(3,-1)0.75 (2,5.5)(0.5,0.5)2(1,-1)0.5
(3.25,6.5)(0.75,0.25)2(1,-3)0.25 (4.75,6)(0.75,-0.25)2(1,3)0.25
(6,5.5)(0.5,-0.5)2(1,1)0.5 (6.75,4.5)(0.25,-0.75)2(3,1)0.75
(6.75,2.5)(0.25,0.75)2(3,-1)0.75 (6,1.5)(0.5,0.5)2(1,-1)0.5
(4.75,1)(0.75,0.25)2(1,-3)0.25 (3.25,0.5)(0.75,-0.25)2(1,3)0.25
(2,1.5)(0.5,-0.5)2(1,1)0.5 (1.25,3)(0.25,-0.75)2(3,1)0.75

(1,3.4)=C= (1.1,3.75)(0,1)0.5 (7.85,3.4)=P= (7.95,3.3)(0,-1)0.5

(1.5,3.4) (1.65,4.25) (1.95,5) (2.25,5.4) (2.75,5.8) (3.5,6.15)
(4.25,6.3) (5,6.15) (5.75,5.8) (6.25,5.4) (6.75,5) (7,4.25) (7.25,3.4)

Die Synchronisation von /producer/ und /consumer/ erfolgt über
verallgemeinerte (nicht binäre) Semaphoroperationen.

**** Semaphoroperationen:
     :PROPERTIES:
     :CUSTOM_ID: semaphoroperationen
     :END:

=down=, =up=

=down(s)\\
wenn s>0\\
dann s:=s-1\\
sonst blockiere laufenden Prozess

=up(s)\\
s:=s+1\\
löse auf s wartenden Prozess\\
aus Wartezustand

Die Prozesse benutzen jeweils eine Kommunikationsprozedur,
=SendeNachricht= und =EmpfangeNachricht=, die dafür sorgen, dass der
Erzeuger wartet, wenn der Puffer voll ist, und der Verbraucher, wenn der
Puffer leer ist.

#+BEGIN_EXAMPLE
    EmpfangeNachricht(puffer,nachricht)
       down(voll)
       P(sp)
       nachricht:=puffer.nachricht[puffer.c]
       puffer.c:=puffer.c+1 mod max
       V(sp)
       up(leer)
       
    SendeNachricht(puffer,nachricht)
       down(leer)
       P(sp)
       puffer.nachricht[puffer.p]:=nachricht
       puffer.p:=puffer.p+1 mod max
       V(sp)
       up(voll)

    Initialisierung:
       leer:=max
       voll:=0
       sp:=1
       p:=0
       c:=0
#+END_EXAMPLE

Der Nachteil dieser Lösung des Synchronisationsproblems liegt darin, dass
die Verantwortung für die korrekte Synchronisation bei den Prozessen
bzw. deren korrekte Programmierung liegt. Programmierfehler können dabei
zu schwer reproduzierbarem Fehlverhalten (z.B. Verklemmungen) führen.

Abhilfe schafft z.B. dass von Hoare bzw. Brinch Hansen
(\cite{Brinch Hansen}) beschriebene

**** Monitor-Konzept
     :PROPERTIES:
     :CUSTOM_ID: monitor-konzept
     :END:

 \\
das eine, wie in Abbildung [Monitor] gezeigt, hierarchische Struktur
vorsieht. Dabei sind alle kritischen Abschnitte als Routinen des
Monitors implementiert.

(10,3) (0,0)(4,1)Prozess A (3,2)(4,1)Monitor (6,0)(4,1)Prozess B
(2,1)(1,1)1 (8,1)(-1,1)1

** Synchronisation durch Nachrichtenaustausch
   :PROPERTIES:
   :CUSTOM_ID: synchronisation-durch-nachrichtenaustausch
   :END:

Die bisher betrachteten Synchronisationsprimitive sind nur einsetzbar,
wenn die beteiligten Prozesse Zugriff auf einen gemeinsamen
Speicherbereich (shared memory) haben, in dem sich z.B. die
Semaphorvariablen befinden. Auf diese Art ist daher die Synchronisation
in Verteilten Systemen, wo Prozesse auf unterschiedlichen Maschinen
ablaufen können, nicht möglich.

Hierfür werden neue Synchronisationsprimitive (Aufrufe des Systemkerns),
die auf dem Austausch von Nachrichten (/message passing/) basieren,
eingeführt:

-  =send(destination,message)=

-  =receive(source,message)=

Mit =send= und =receive= können Prozesse synchronisiert werden, die auf
Prozessoren ohne gemeinsamen Speicher ablaufen. Bei einem Aufruf von
=send= wird der Prozess blockiert, wenn keine Nachricht übermittelt
werden kann. Bei einem Aufruf von =receive= wird der Prozess blockiert,
wenn keine Nachricht verfügbar ist.

Mögliche Schwierigkeiten bei der Nachrichtenübermittlung:

-  Verlust einer Nachricht\\
   Abhilfe: jede gesendete Nachricht muss quittiert werden (
   /acknowledgement/), wiederholen der Nachricht beim Ausbleiben der
   Quittung

-  Verlust der Quittung

-  doppeltes Eintreffen einer Nachricht beim Empfänger\\
   Abhilfe: Numerieren der Nachrichten

-  Eindeutige Benennung (Adressierung) von:

   -  Prozessoren

   -  Maschinen

   -  /domains/

-  Sicherheitsprobleme

-  Effizienz, wenn Sender und Empfänger auf der gleichen Maschine laufen

***** Behandlung des /Producer-Consumer-Problems/ mit /message passing/:
      :PROPERTIES:
      :CUSTOM_ID: behandlung-des-producer-consumer-problems-mit-message-passing
      :END:

 \\
Annahmen:

-  Nachrichten haben feste Länge.

-  gesendete, aber noch nicht empfangene Nachrichten werden vom
   Betriebssystem automatisch gepuffert.

-  maximal =max= Nachrichten können gepuffert werden.

#+BEGIN_EXAMPLE
    Consumer:
        for i := 1 to max do send(producer,emptymessage);
        while true do begin
           receive(producer,message);
           extract_data(message);
           send(producer,emptymessage);
           process(data);
        end

    Producer:
        while true do begin
           produce_data(data);
           receive(consumer,emptymessage);
           build_message(message,data);
           send(consumer,message);
        end
#+END_EXAMPLE

***** Anmerkungen:
      :PROPERTIES:
      :CUSTOM_ID: anmerkungen
      :END:

-  die Zahl der Nachrichten bleibt konstant

-  für Pufferung ist ein fester Speicherbereich vorgesehen

-  Pufferung und Adressierung erfolgt durch sog. /mailboxes/ bei Sender
   und Empfänger

-  /Rendez-vous-Technik/: Kommunikation ohne Pufferung

-  in UNIX entsprechen sogenannte /pipes/ den /mailboxes/

* Verklemmungen
  :PROPERTIES:
  :CUSTOM_ID: verklemmungen
  :END:

**** Definition:
     :PROPERTIES:
     :CUSTOM_ID: definition-1
     :END:

Eine Verklemmung (/deadlock/) bedeutet, dass zwei oder mehr Prozesse auf
Ereignisse warten, die niemals eintreten werden
("Nach-Ihnen-Nach-Ihnen"-Schleifen, Warten im "Kreis").

**** Beispiel:
     :PROPERTIES:
     :CUSTOM_ID: beispiel
     :END:

Verschachtelung von kritischen Abschnitten

| P1   | :   | P(a)   | ...   | P(b)   | ...   | V(b)   | ...   | V(a)   |
| P2   | :   | P(b)   | ...   | P(a)   | ...   | V(a)   | ...   | V(b)   |

Das Auftreten von Verklemmungen ist zeitabhängig. Ursachen sind im
laufenden System schwer feststellbar und nicht ohne weiteres
reproduzierbar. Das Problem wurde zuerst von Edsger W. Dijkstra1965
erkannt und analysiert.

**** Vier notwendige Bedingungen für das Auftreten von Verklemmungen:
     :PROPERTIES:
     :CUSTOM_ID: vier-notwendige-bedingungen-für-das-auftreten-von-verklemmungen
     :END:

1. "Wechselseitiger Ausschluss"-Bedingung:\\
   Ein Betriebsmittel, um das Prozesse konkurrieren, ist entweder frei
   oder genau einem Prozess zugewiesen.

2. "Halte-und-warte"-Bedingung:\\
   Prozesse mit bereits zugewiesenen Betriebsmitteln dürfen weitere
   Betriebsmittel anfordern.

3. "/No-preemption/"-Bedingung:\\
   Prozesse geben Betriebsmittel nur von sich aus frei. Betriebsmittel
   können ihnen nicht zwangsweise entzogen werden.

4. "/Circular-wait/"-Bedingung:\\
   Zwei oder mehr Prozessse warten wechselseitig auf Betriebsmittel, die
   von dem/den jeweils anderen gehalten werden.

Die vierte Bedingung wird, wie in Abbildung [deadlock] gezeigt, zur
Modellierung von Verklemmungssituationen durch Graphen zum Zwecke der
Verklemmungserkennung benutzt.

#+CAPTION: [deadlock] Modellierung einer Verklemmungssituation durch
einen Graphen
[[file:deadlock.eps]]

**** Vier Strategien mit dem Verklemmungsproblem umzugehen:
     :PROPERTIES:
     :CUSTOM_ID: vier-strategien-mit-dem-verklemmungsproblem-umzugehen
     :END:

1. "Vogel-Strauss"-Algorithmus (Beispiel: UNIX)

2. Erkennung und Auflösung (Beispiel: Datenbanktransaktionen)

3. Verklemmungsfreiheit durch besondere Zuteilungsalgorithmen
   (Verklemmungsvermeidung, /deadlock avoidance/)

4. Verhinderung von Verklemmungen durch Aufheben einer der vier
   notwendigen Bedingungen

**** Beispiele für Verhinderungsmaßnahmen:
     :PROPERTIES:
     :CUSTOM_ID: beispiele-für-verhinderungsmaßnahmen
     :END:

1. mehrfachen Zugriff erlauben (Bedingung 1. ist aufgehoben)\\
   Im allgemeinen nicht sinnvoll.

2. /preemptive scheduling/ (Bedingung 3. ist aufgehoben)\\
   Bei CPU selbstverständlich, bei E/A-Geräten meist nicht sinnvoll.

3. Vorwegzuteilung aller von einem Prozess benötigten Betriebsmittel

   -  im Prinzip möglich

   -  Nachteil: Parallelität stark eingeschränkt

   -  Betriebsmittelbedarf muss im Vorhinein bekannt sein.

**** Verklemmungsvermeidung
     :PROPERTIES:
     :CUSTOM_ID: verklemmungsvermeidung
     :END:

beruht auf der Grundidee, die Betriebsmittelanforderungen der Prozesse
in eine "verklemmungsfreie" Reihenfolge zu bringen. Die Algorithmen
(Vgl. Bankiersalgorithmus) hierfür sind teiweise sehr komplex und auch
nur anwendbar, wenn der gesamte Betriebsmittelbedarf der Prozesse im
vorhinein bekannt ist, was in der Praxis häufig nicht der Fall ist.
Nichtsdestotrotz hat sich um dieses Thema herum eine eigene
mathematische Theorie entwickelt, auf die hier aber nicht eingegangen
wird.

* Prozessorverwaltung
  :PROPERTIES:
  :CUSTOM_ID: prozessorverwaltung
  :END:

** Funktion des Schedulers
   :PROPERTIES:
   :CUSTOM_ID: funktion-des-schedulers
   :END:

**** Kurzfristige Steuerung (/short term scheduling/):
     :PROPERTIES:
     :CUSTOM_ID: kurzfristige-steuerung-short-term-scheduling
     :END:

Zuteilung von Betriebsmitteln (hier CPU) zu Prozessen, sobald
ver"-füg"-bar, bei möglichst guter Auslastung der Betriebsmittel und
fairer Behandlung aller Prozesse. Sie stellt die
Synchronisationsprimitive zur Verfügung.

(Daneben gibt es die - hier nicht behandelte - mittelfristige Steuerung,
die auf der Job-Ebene angesiedelt ist und einzelnen Prozessen bzw. Jobs
z.B. auf der Basis von Benutzerklassen oder des zu erwartenden Speicher-
und Rechenzeitbedarfs Prioritäten für die Betriebsmittelvergabe
zuweist.)

Für die folgenden Betrachtungen gehen wir von einer Systemkonfiguration
aus, bei der die Zahl der Prozesse im Hauptspeicher grösser ist als die
Zahl der Prozessoren.

**** Prozessbeschreibung
     :PROPERTIES:
     :CUSTOM_ID: prozessbeschreibung
     :END:

***** Prozesszustände:
      :PROPERTIES:
      :CUSTOM_ID: prozesszustände
      :END:

-  *beendet*\\
   Prozess, der beendet bzw. nicht vorhanden ist.

-  *rechnend*\\
   Prozess, dem ein Prozessor zugeordnet ist.

-  *wartend*\\
   Prozess, der auf den Eintritt eines Ereignisses wartet.

-  *bereit*\\
   Prozess, der gestartet oder fortgesetzt werden kann, dem aber noch
   kein Prozessor zugeteilt wurde.

Abbildung [Zustandsübergänge] zeigt die möglichen Zustandsübergänge. Im
folgenden werden die diese Übergänge auslösenden Operationen bzw.
Situtationen beschrieben.

#+CAPTION: [Zustandsübergänge] Mögliche Zustandsübergänge für einen
Prozess
[[file:prozessdiagramm.eps]]

Der Übergang vom Zustand =rechnend= in den Zustand =bereit= erfolgt hier
durch die sogenannte /Verdrängung/ (/preemptive scheduling/) - auch
/unterbrechende Steuerung/ genannt. Der einfachere Fall, dass ein Prozess
den Prozessor von sich aus abgibt (Prozess rechnet bis er fertig ist),
wird hier nicht weiter betrachtet.

***** Prozesskontrollblöcke:
      :PROPERTIES:
      :CUSTOM_ID: prozesskontrollblöcke
      :END:

 \\
Das Betriebssystem (genauer: der Scheduler) verwaltet die Prozesse in
einer aus /Prozesskontrollblöcken/ (PKB) bestehenden Prozesstabelle:.\\
PKB=registerfeld[1..n]\\
{für die Aufnahme der Registerinhalte incl PC}\\
prozesstabelle[1..p] von PKB\\
{Index identifiziert Prozess}\\

Ein Prozess ist durch seinen PKB und seinen Zustand beschrieben. Für die
unterbrechende Steuerung ist ein Zeitgeber erforderlich, der den
Prozessor periodisch unterbricht und den Scheduler aufruft. Die
Intervallänge bestimmt den Rhythmus der Prozessorzuteilung. Sehr kurze
Intervalle bringen viel "Overhead", sehr lange Intervalle behindern
eventuell Prozesse höherer Priorität.

Zeitgeber:

==wiederhole\\
Uhr:=intervalllänge\\
wiederhole\\
uhr:=uhr-1\\
bis uhr=0\\
setze interrupt\\
ständig\\

Befehlszyklus:

==wiederhole\\
wenn interrupt und intErlaubt\\
dann rücksetze interrupt\\
interruptbehandlung\\
monitor(verdrängeProzess)\\
führe aktuellen Befehl aus\\
ständig

Die =interruptbehandlung= prüft die Ursache der Unterbrechung und führt
die Routine =monitor(verdrängeProzess)= nur dann aus, wenn die
Unterbrechung durch den Zeitgeber ausgelöst wurde. Da alle Prozessoren
denselben =monitor= benutzen, stellt dieser einen kritischen Abschnitt
dar. Der *Monitor* hat folgenden Aufbau:

==monitor(funktion)\\
teste und setze(sm)\\
prozesstabelle[aktiverProzess].registerfeld:=Prozessorregister\\
CASE funktion\\
$\left.\begin{array}{l}\vdots\\\mbox{verdrängeProzess}\\\vdots\end{array}\right\}\mbox{\textrm{scheduling}}$\\
prozess:=aktiverProzess\\
Prozessorregister:=prozesstabelle[prozess].registerfeld\\
sm:=1\\
end-monitor

Das Retten und Zurückholen der Prozessorregister bezeichnet man auch als
/context switching/. =aktiverProzess= ist aus der Menge der
rechenwilligen Prozesse zu ermitteln (verwaltet in einer Liste, der
=bereitliste=). Die =bereitliste= kennt zwei Funktionen:

-  =einfüge(prozess,bereitliste)=, um einen Prozess der Liste hinzuzufügen

-  =entferne(prozess,bereitliste)=, um einen Prozess aus der Liste zu
   entfernen

Mithilfe dieser Funktionen kann die Monitorroutine =verdrängeProzess=
implementiert werden.

==verdrängeProzess\\
einfüge(prozess,bereitliste)\\
entferne(prozess,bereitliste)

Die Bereitsliste enthält immer mindestens einen rechenwilligen Prozess,
den sogenannten Nullprozess, der bei der Systeminitialisierung zum
aktiven Prozess gemacht wird.

**** Weitere scheduler-Routinen
     :PROPERTIES:
     :CUSTOM_ID: weitere-scheduler-routinen
     :END:

:

==starteProzess(anfangszustand)\\
hole freien PKB(neuerProzess)\\
prozesstabelle[neuerProzess].registerfeld:=anfangszustand\\
einfüge(neuerProzess,bereitliste)

==beende(prozess) {Prozess beendet sich selbst}\\
PKB freigeben\\
entferne(aktiverProzess,bereitliste)

**** Semaphoroperationen
     :PROPERTIES:
     :CUSTOM_ID: semaphoroperationen-1
     :END:

Die im Abschnitt 2.2 beschriebenen Semaphoroperationen =up= und =down=
können auch als Monitorroutinen implmentiert werden. Dabei ist jeder
Semaphore folgende Struktur zugeordnet:

#+BEGIN_EXAMPLE
        semaphore[sem] = record
                           zaehler
                           warteschlange
                         end
#+END_EXAMPLE

Damit ergibt sich für =up= und =down=:

#+BEGIN_EXAMPLE
        down(sem):
           wenn semaphore[sem].zaehler > 0
           dann semaphore[sem].zaehler := semaphore[sem].zaehler - 1
                aktiverProzess := prozess {oder verdraenge(prozess)}
           sonst einfuege(semaphore[sem].warteschlane, prozess)
                 entferne(bereitliste, aktiverProzess)
        
        up(sem):
           wenn nicht leer(semaphore[sem].warteschlange)
           dann entferne(semaphore[sem].warteschlange, aktiverProzess)
                eifuege(bereitliste, aktiverProzess)
           sonst semaphore[sem].zaehler := semaphore[sem].zaehler + 1
           aktiverProzess := prozess {oder verdraenge(prozess)}
#+END_EXAMPLE

Diese Implementierungen benutzen nicht mehr die "beschäftigte Form des
Wartens".

** Steuerungsstrategien (/scheduling strategies/)
   :PROPERTIES:
   :CUSTOM_ID: steuerungsstrategien-scheduling-strategies
   :END:

1. */round robin/ scheduling:*\\
   Jeder Prozess erhält ein festes Zeitquantum. Wenn dieses abgelaufen
   ist, wird auf den nächsten Prozess umgeschaltet. Der unterbrochene
   Prozess kommt ans Ende der =bereitliste=. Es handlet sich um eine
   einfache, faire und häufig benutzte Strategie.\\
   Parameter: Länge des Zeitquantums

   -  zu kurz: Verwaltungsaufwand (/context switching/) wird sehr hoch

   -  zu lang: Antwortzeiten werden lang

   Erfahrungswert: $100ms$

2. *Prioritätssteuerung:*\\
   Prozesse haben unterschiedliche Prioritäten und werden danach
   eingeplant. Nur der Prozess mit der höchsten Priorität darf rechnen.
   Um "Langläufer" zu "bremsen" könnte der Scheduler die Priorität
   schrittweise vermindern. Die Priorität kann /statisch/ oder
   /dynamisch/ zugeordnet werden. Bei dynamischer Zuordnung ändert sich
   die Priorität nach bestimmten Regeln:

   -  I/O-bound $\to$ hohe Priorität

   -  CPU-bound $\to$ niedrige Priorität

   Einfache Zuordnungsformel: $p=\frac{1}{f}$, mit $f=$ benutzter Anteil
   des Prozesses an der Rechenzeit während des letzten Zeitquantums.

   *Erweiterung durch Prioritätsklassen:*

   -  Jeder Prozess wird einer Klasse zugeordnet.

   -  Innerhalb einer Klasse wird nach /round robin/ scheduling
      verfahren

   Prozesse der zweiten Klasse werden erst bedient, wenn die höchste
   Klasse leer ist.

3. */shortest job first/:*\\
   Diese Methode ist anwendbar für Prozesse, deren Gesamtrechenzeit
   bekannt ist (z.B. /batch-jobs/). *Beispiel:* angenommene Jobfolge:\\

   | Job-Nr.:    | 1    | 2    | 3    | 4    | 5   |
   | CPU-Zeit:   | 20   | 10   | 50   | 15   | 5   |

   \\
   Die durchschnittliche Rechenzeit (Verweildauer) ergibt:\\

   in der Reihenfolge: $$\begin{array}{rrl}
       1: & 20 \\
       2: & 30 \\
       3: & 80 \\
       4: & 95 \\
       5: & 100 & \\ \hline
       \sum & 325 & \div 5 = 65
       \end{array}$$

   shortest job first: $$\begin{array}{rrl}
       5: & 5 \\
       2: & 15 \\
       4: & 30 \\
       1: & 50 \\
       3: & 100 & \\ \hline
       \sum & 200 & \div 5 = 40
       \end{array}$$

   \\
   $\Rightarrow$ Die durchschnittliche Rechenzeit wird minimiert.

4. *guaranteed scheduling:*\\
   z.B. Realzeitsysteme

5. *Scheduling mit Verdrängung von Prozessen*\\

   -  Auslagern eines Prozesses (/swapping/)

   -  zwei-Ebenen-Scheduling\\
      1.Ebene: Scheduling der Prozesse im Hauptspeicher\\
      2.Ebene: Ein-/Auslagern von Prozessen

* Zusammenfassung
  :PROPERTIES:
  :CUSTOM_ID: zusammenfassung
  :END:

Sequentielle Prozesse sind Abstraktionsmittel, um von Details auf
Maschinenebene (z.B. Interrupts) abstrahieren zu können Ein
Betriebssystem ist eine Sammlung parallel ablaufender sequentieller
Prozesse. Jeder Prozess hat eigene virtuelle Betriebsmittel.

Weitere wichtige Konzepte:

-  Konzept des kritischen Abschnittes

-  Prozess-Synchronisations-Primitive

-  Prozesszustände

-  Scheduling-Strategien


